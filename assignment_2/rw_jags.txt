model {
  
    # infer starting parameters
  Q[1,1] ~ dgamma(1, .5)
  Q[1,2] ~ dgamma(1, .5)
  
    # infer internal states
  alpha  ~ dunif(0,1)
  beta ~ dgamma(1, .5)
  
  for (t in 2:n_trials){
    for (k in 1:2){
      # update utility Q for chosen option with reward on last trials
      Q_update[t, k] <- Q[t-1, k] + alpha*(r[t-1] - Q[t-1, k])
      Q[t, k] <- ifelse(k==choice[t-1], Q_update[t, k], Q[t-1, k])
      exp_p[t, k] <- exp(beta*Q[t,k])
    }
    for (k in 1:2){
      p[t,k] <- exp_p[t,k]/sum(exp_p[t,])
    }
    
      # make choice
    choice[t] ~ dcat(p[t,1:2])
  }
}
