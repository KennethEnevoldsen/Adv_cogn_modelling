---
title: "rescorla_wagner"
author: "K. Enevoldsen"
date: "2/26/2020"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup}
pacman::p_load(pacman, tidyverse, R2jags, modules, patchwork, cvms,
               extraDistr # for extra destributions
               )
set.seed(1994)
agents <- modules::import(module = "../jags_helpfuns/agents", attach = T, doc = T)
modules::reload(agents)
qc <- modules::import("../jags_helpfuns/quick_n_clean_plots", attach = T, doc = T)
modules::reload(qc)
jh <- modules::import("../jags_helpfuns/jags_helpfuns", attach = T, doc = T)
modules::reload(jh)
```

```{r payoff}
# generate payoff matrix for bandit task
  # choice of bandit A - 30% of a payoff 2, otherwise 0
  # Choice of bandit B - 70% of a payoff 1, otherwise 0

bandit_payoff <- function(ntrials = 100, choice = "a", a_prop = 0.3, a_reward = 2, b_prop = 0.7, b_reward = 1){
  if (choice == "a"){
    return(rbinom(ntrials, 1, a_prop)*a_reward)
  } else if (choice == "b"){
    return(rbinom(ntrials, 1, b_prop)*b_reward)
  }
}

payoff <- cbind(bandit_payoff(choice = "a"), bandit_payoff(choice = "b"))
```


```{r jags models rb} 
model <- "model {
  theta ~ dunif(0, 1)
  b[1] <- theta
  b[2] <- 1-theta
  
  for (t in 1:n_trials){
    choice[t] ~ dcat(b) # categorical distribution
  }
}
"

writeLines(model, "RB_jags.txt")
```


# sim an fit RB
```{r sim}
rb_sim <- agents$RB(theta = 0.7, payoff = payoff)
rb_sim


# fit
samples <- jags.parallel(data = list(choice = rb_sim$choices, n_trials = length(rb_sim$choices)), 
                inits = NULL, 
                parameters.to.save = c("theta"), 
                model.file =  "RB_jags.txt", 
                n.chains = 4, n.iter = 5000, n.burnin = 1000 # warm-up
                )



qc$plot_dens(x = samples$BUGSoutput$sims.list$theta)
qc$plot_scatter(x = samples$BUGSoutput$sims.list$theta)
# qc$plot_dens_gif(x = samples$BUGSoutput$sims.list$theta)
```


# parameters recovery RB
```{r}
n_reps = 10

res <- NULL
for (i in 1:n_reps){
  print(paste("Curenntly running", i, "out of", n_reps, sep = " "))
    # sim
  theta = runif(1, 0, 1)
  rb_sim <- agents$RB(theta = theta, payoff = payoff)
  
    # fit
  samples <- jags.parallel(data = list(choice = rb_sim$choices, n_trials = length(rb_sim$choices)), 
                inits = NULL, 
                parameters.to.save = c("theta"), 
                model.file = "RB_jags.txt",
                n.chains = 4, n.iter = 5000, n.burnin = 1000 # warm-up
                )
  
  tmp <- tibble(theta_true = theta, map_theta = jh$jag_map(samples$BUGSoutput$sims.list$theta))
  
  res[[i]] <- tmp
}
results <- res %>% do.call(rbind, .)

plot(results$theta_true, results$map_theta)
qc$plot_actual_predicted(actual = results$theta_true, results$map_theta)
```


```{r}
payoff <- cbind(bandit_payoff(ntrials = 100, choice = "a", a_prop = .3, a_reward = 2), 
                bandit_payoff(ntrials = 100, choice = "b", b_prop = .8, b_reward = 1.5))

```

```{r jags models rw}
model <- "model {
  
    # infer starting parameters
  Q[1,1] ~ dt(0, .16, 1)T(0,) # half cauchy
  Q[1,2] ~ dt(0, .16, 1)T(0,)
  
    # infer internal states
  alpha  ~ dunif(0,1)
  beta ~ dt(0, .16, 1)T(0,)
  
  for (t in 2:n_trials){
    for (k in 1:2){
      # update utility Q for chosen option with reward on last trials
      Q_update[t, k] <- Q[t-1, k] + alpha*(r[t-1] - Q[t-1, k])
      Q[t, k] <- ifelse(k==choice[t-1], Q_update[t, k], Q[t-1, k])
      exp_p[t, k] <- exp(beta*Q[t,k])
    }
    for (k in 1:2){
      p[t,k] <- exp_p[t,k]/sum(exp_p[t,])
    }
    
      # make choice
    choice[t] ~ dcat(p[t,1:2])
  }
}"


writeLines(model, "rw_jags.txt")
```

```{r rescorla wagner sim}
  # sim
res <- agents$rw(payoff, alpha = 0.3, beta = 2)

samples <- jags.parallel(data = list(choice = res$choice, n_trials = length(res$choice), r = res$reward), 
                inits = NULL, 
                parameters.to.save = c("alpha", "beta"), 
                model.file = "rw_jags.txt",
                n.chains = 4, n.iter = 2000, n.burnin = 1000 # warm-up
                )

qc$plot_agent_rw(alpha_sample = samples$BUGSoutput$sims.list$alpha,
                 true_alpha = 0.3, 
                 beta_sample = samples$BUGSoutput$sims.list$beta,
                 true_beta = 2, 
                 choice = res$choice-1, 
                 p_1 = res$p[,2], 
                 reward = res$reward,
                 Q1 = res$Q[,1], 
                 Q2 = res$Q[,2])
```



```{r choice kernel agent}
choice_kernel <- function(payoff, alpha, beta){
  n_trials = nrow(payoff)
  choice <- array(0, c(n_trials))
  r <- array(0, c(n_trials))
  ck <- array(0, c(n_trials, 2)) # choice kernel
  ck_chosen <- array(0, c(n_trials, 2)) 
  ck_unchosen <- array(0, c(n_trials, 2)) 
  p <- array(0, c(n_trials, 2))
  exp_p <- array(0, c(n_trials, 2))

    # trial1
  ck[1,1] <- 1
  ck[1,2] <- 1
  
  choice[1] <- extraDistr::rcat(1, c(0.5, 0.5))
  r[1] <- payoff[1, choice[1]]
  
  
  for (t in 2:n_trials){
    for (k in 1:2){
      # learn
      ck_chosen[t,k] <- ck[t-1,k] + alpha*(1-ck[t-1,k])
      ck_unchosen[t,k] <- ck[t-1,k] + alpha*(0-ck[t-1,k])
      
      ck[t, k] <- ifelse(k == choice[t-1], ck_chosen[t, k], ck_unchosen[t, k])

      exp_p[t, k] <- exp(beta * ck[t, k])
    }
    for (k in 1:2){
      p[t, k] <- exp_p[t, k] / sum(exp_p[t,])
    }

    choice[t] <- extraDistr::rcat(1, p[t,])
     # get reward
    r[t] <- payoff[t, choice[t]]
  }
    
  return(list(choice = choice, 
              reward = r, 
              ck = ck, 
              p = p,
              start_params = list(alpha = alpha, beta = beta)))
}


ck_sim <- choice_kernel(payoff, alpha = 0.5, beta = 1)
ck_sim$start_params

p1 <- qc$plot_choice(choice = ck_sim$choice -1, 
               p_1 = ck_sim$p[, 2], 
               reward = ck_sim$reward)
p1
p2 <- qc$plot_rw_q(Q1 = res$ck[,1], Q2 = res$ck[,2])
```


```{r jags models choice kernel}
model <- "model {
    # infer starting parameters
  ck[1,1] ~ dt(0, .16, 1)T(0,) # half cauchy 
  ck[1,2] ~ dt(0, .16, 1)T(0,) 
  
    # infer internal states
  alpha  ~ dunif(0,1)
  beta ~ dt(0, .16, 1)T(0,)
  
  for (t in 2:n_trials){
    for (k in 1:2){
      # learn
      ck_chosen[t,k] <- ck[t-1,k] + alpha*(1-ck[t-1,k])
      ck_unchosen[t,k] <- ck[t-1,k] + alpha*(0-ck[t-1,k])
      
      ck[t, k] <- ifelse(k == choice[t-1], ck_chosen[t, k], ck_unchosen[t, k])

      exp_p[t, k] <- exp(beta * ck[t, k])
    }
    for (k in 1:2){
      p[t, k] <- exp_p[t, k] / sum(exp_p[t,])
    }

    choice[t] ~ dcat(p[t,1:2])
  }
}"

writeLines(model, "choice_kernel_jags.txt")
```

```{r fit kernel jags}
ck_sim <- agents$choice_kernel(payoff, alpha = 0.3, beta = 1)

n = 2000
p_load(runjags)

?run.jags(method = "rjparallel")
samples <- xsjags.parallel(data = list(choice = ck_sim$choice, n_trials = length(ck_sim$choice)), 
                inits = NULL, 
                parameters.to.save = c("alpha", "beta"), 
                model.file = "choice_kernel_jags.txt",
                n.chains = 4, n.iter =  n, n.burnin = 1000 # warm-up
                )
qc$plot_dens(samples$BUGSoutput$sims.list$alpha)
qc$plot_dens(samples$BUGSoutput$sims.list$beta)

```



```{r sim}
payoff_gen_fun = "jh$bandit_payoff(100, probs = c(.3, .8), reward = c(1, 1.5))"
agent_gen_fun = list(rw = "agents$rw(payoff, alpha = runif(1, 0,1), beta = runif(1, 0.5, 3))",
               rb = "agents$RB(payoff, theta = runif(1, 0,1))",
               ck = "agents$choice_kernel(payoff, alpha = runif(1, 0,1), beta = runif(1, 0.5, 3))") 
params_to_save = list(rw = c("alpha", "beta"),
                      rb = c("theta"),
                      ck = c("alpha", "beta"))
model_filepath = list(rw = "rw_jags.txt",
                      rb = "RB_jags.txt",
                      ck =  "choice_kernel_jags.txt")

# just simulate it 100 times
results <- jh$simulate_fit(payoff_gen_fun, agent_gen_fun, params_to_save, model_filepath, save_samples = T, n_sim = 100)

results %>% write_csv(., "n_sim_100")


### model recovery
rename_cols <- c(rw="Rescorla-wagner", rb="Random bias", ck="Choice-kernel")
res <- results %>%
  select(-c(samples, true_params)) %>%  
  group_by(n_sim, model_generating_the_data) %>% 
    # arrange and pick best according to BIC
  arrange(BIC) %>% 
  slice(1) %>% 
  ungroup %>% 
    # mutate columns
  mutate(model_generating_the_data = recode(model_generating_the_data, !!!rename_cols),
         best_fit_model =            recode(model_fitted_to_data,      !!!rename_cols)
         ) %>% 
  select(-model_fitted_to_data) %>% 
  mutate_at(c("model_generating_the_data", "best_fit_model"), factor, levels = rename_cols) 


cm <- res %>% 
  cvms::evaluate(., target_col = model_generating_the_data, prediction_cols = best_fit_model, type = "binomial") 
cvms::plot_confusion_matrix(cm, add_zero_shading = F)


### parameter recovery
rename_cols <- c(rw="Rescorla-wagner", rb="Random bias", ck="Choice-kernel")
results$samples[[1]]


get_true_actual <- function(data, agent, parameters, ci = 0.89, remove_col = c("samples", "BIC", "true_params")){
  # currently using MAP
  res = data %>% 
    filter(model_generating_the_data == agent & model_fitted_to_data == agent)
  
  

  # get map
  for (parameter in parameters){
    res[[paste(parameter, "map", sep = "_")]] <- sapply(res$samples,  function(x) jh$jag_map(x[[parameter]]) )
    
    # get CI

    res[[paste(parameter, "ci_low", sep = "_")]]  <- sapply(res$samples,  function(x) bayestestR::ci(x[[parameter]], ci = ci)$CI_low)
    res[[paste(parameter, "ci_high", sep = "_")]] <- sapply(res$samples,  function(x) bayestestR::ci(x[[parameter]], ci = ci)$CI_high)
    
  }
  
  # get true params
  for (parameter in parameters){
    res[[paste(parameter, "true", sep = "_")]] <- sapply(res$true_params,  function(x) x[[parameter]] )
  }
  
  if (length(remove_col)>1){
    remove_col = colnames(res)[colnames(res) %in% remove_col]
    res <- res %>% select(-remove_col)
  }
  return(res)
}


rw_ap <- get_true_actual(results, agent = "rw", parameters = c("alpha", "beta"))
p1 <- qc$plot_actual_predicted(actual = rw_ap$alpha_true, predicted = rw_ap$alpha_map) + xlim(0,NA) + ylim(0,NA)
p1 + geom_pointrange(aes(x = rw_ap$alpha_true,
                       ymin = rw_ap$alpha_ci_low, 
                       ymax = rw_ap$alpha_ci_high), alpha = 0.3)

p2 <- qc$plot_actual_predicted(actual = rw_ap$beta_true, predicted = rw_ap$beta_map) + xlim(0,NA) + ylim(0,NA)
p2 + geom_pointrange(aes(x = rw_ap$beta_true,
                       ymin = rw_ap$beta_ci_low, 
                       ymax = rw_ap$beta_ci_high), alpha = 0.3)
d <- (p1 + p2)



rb_ap <- get_true_actual(results, agent = "rb", parameters = c("theta"))
qc$plot_actual_predicted(actual = rb_ap$theta_true, predicted = rb_ap$theta_map)

ck_ap <- get_true_actual(results, agent = "ck", parameters = c("alpha", "beta"))
qc$plot_actual_predicted(actual = ck_ap$alpha_true, predicted = ck_ap$alpha_map)
qc$plot_actual_predicted(actual = ck_ap$beta_true, predicted = ck_ap$beta_map)

```








